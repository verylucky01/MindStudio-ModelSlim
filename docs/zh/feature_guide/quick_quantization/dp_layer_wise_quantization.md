# 分布式逐层量化特性说明

## 简介

DP逐层量化（Distributed Data Parallel Layer-wise Quantization）是在逐层量化的基础上，通过在多设备上数据并行（Data Parallel）来显著提升量化效率，同时保持逐层量化的内存优势。

## 使用前准备

安装 msModelSlim 工具，详情请参见[安装指南](../../install_guide.md)。

## 功能介绍

### 配置方法

在量化入口指定`device`参数为多张NPU卡，系统会自动检测多卡配置并启用DP逐层调度器。

**命令行示例**：
```bash
# 使用4张NPU卡进行量化
msmodelslim quant --model_path ${MODEL_PATH} --save_path ${SAVE_PATH} --device npu:0,1,2,3 --model_type ${MODEL_TYPE}--quant_type w8a8 --trust_remote_code True
```

可以在yaml配置文件中直接指定`runner`为`dp_layer_wise`。如果`runner`未设置（默认为`auto`）或设置为`auto`，系统会自动检测多卡配置并启用DP逐层调度器。

**配置示例**：
```yaml
apiversion: "modelslim_v1"
spec:
  runner: "dp_layer_wise"  # 显式启用分布式逐层量化
  process:
    - type: "linear_quant"
      qconfig:
        act:
          scope: "per_tensor"
          dtype: "int8"
          symmetric: false
          method: "minmax"
        weight:
          scope: "per_channel"
          dtype: "int8"
          symmetric: true
          method: "minmax"
      include: ["*"]
```

**说明**：
- 显式配置`runner: "dp_layer_wise"`时，需要确保`device`参数指定了多个设备
- 如果设备数量≤1，系统会发出警告并回退到单卡逐层量化


## 功能介绍

### 工作原理

| 量化方式 | 处理方式 | 内存占用 | 特点 | 适用场景 |
|----------|----------|----------|------|----------|
| 单卡逐层量化 | 单设备逐层处理 | 单层大小的2-3倍 | 逐层加载参数，流水线操作 | 大模型（≥7B）单卡场景 |
| 分布式逐层量化 | 多设备并行逐层处理 | 单层大小的2-3倍 | 多设备并行，显著提升效率 | 超大模型或大规模校准集场景 |

### 核心优势

| 优势类型 | 单卡逐层方式 | 分布式逐层方式 | 改进效果 |
|----------|-------------|---------------|----------|
| 内存占用 | 单层大小的2-3倍 | 单层大小的2-3倍 | 保持低内存优势 |
| 量化效率 | 单设备串行处理 | 多设备并行处理 | 显著提升量化速度 |
| 资源利用 | 单设备资源 | 多设备资源并行 | 更好的硬件资源利用率 |

### 使用场景

| 场景类型 | 场景描述 | 是否适用 | 说明 |
|----------|----------|----------|------|
| 超大模型量化 | 超大规模模型量化，多卡环境 | ✅ 适用 | 显著提升量化效率 |
| 大规模校准数据 | 大规模校准数据，多卡环境 | ✅ 适用 | 显著提升量化效率 |
| 多卡并行量化 | 需要利用多卡资源加速量化 | ✅ 适用 | 充分利用多卡资源 |

### 加速效果说明

DP分布式多卡量化虽然能显著提升量化速度，但其加速效果受多种因素影响，建议根据校准数据规模与模型复杂度，合理选择并行卡数进行量化，在不浪费资源的同时提高量化效率。


**校准集大小对加速比的影响**

当校准集较小时，单卡处理已经接近I/O或计算瓶颈，此时多卡并行带来的通信开销可能超过并行处理带来的收益，从而导致多卡处理速度不如预期。

**卡数与性能的关系**

虽然在大多数情况下多卡效率优于单卡，但由于引入了额外的通信开销，以及各卡在逐层调度过程中频繁执行的内存加载与结果保存操作为固定耗时，整体量化速度存在理论上限。因此，不能简单地认为卡数越多量化速度就越快。

### 与其他特性的关系

| 特性类型 | 组件名称 | 兼容性 | 说明 |
|----------|----------|--------|------|
| 调度器 | layer_wise_runner | ✅ 完全继承 | DP逐层调度器继承自逐层调度器，具备逐层量化特性 |
| 处理器 | linear_quant | ✅ 完全支持 | 支持分布式逐层量化 |
| 处理器 | iter_smooth | ✅ 完全支持 | 支持分布式执行 |
| 处理器 | flex_smooth | ✅ 完全支持 | 支持分布式执行 |
| 观测器 | minmax量化方法 | ✅ 完全支持 | 支持分布式执行 |
| 观测器 | ssz量化方法 | ✅ 完全支持 | 支持分布式执行 |
| 处理器 | 其他处理器 | ⚠️ 视情况而定 | 需要检查处理器是否支持分布式执行 |
| 保存器 | ascendv1_saver | ✅ 支持 | 自动转换为分布式保存器 |
| 保存器 | distributed_ascendv1_saver | ✅ 支持 | 分布式保存器 |

### 模型适配

DP逐层量化继承自逐层量化，因此支持所有逐层量化适配的大语言模型。请参考[逐层量化特性说明](layer_wise_quantization.md)了解模型适配详情。
**注意**：DP逐层量化暂不支持多模态模型。多模态模型请使用单卡逐层量化（`layer_wise`）。

### 算法适配

DP逐层量化对算法有特定的支持要求，只有支持分布式执行的算法才能在多卡环境下正常工作。

### 支持的算法

#### 离群值抑制算法

| 算法名称 | 处理器类型 | 支持状态 | 说明 |
|----------|----------|---------|------|
| Iterative Smooth | iter_smooth | ✅ 支持 | 完全支持分布式执行 |
| Flex Smooth Quant | flex_smooth | ✅ 支持 | 完全支持分布式执行 |

#### 量化算法

| 算法名称 | 量化方法 | 支持状态 | 说明 |
|----------|---------|---------|------|
| MinMax | minmax | ✅ 支持 | 完全支持分布式执行 |
| SSZ | ssz | ✅ 支持 | 完全支持分布式执行 |

### 注意事项

**重要**：不适配的算法无法启动DP多卡量化。如果配置中包含了不支持分布式执行的算法，系统会在启动时检测并报错，避免在多卡环境下出现异常行为。

在使用DP逐层量化前，请确保：
1. 所有配置的处理器都支持分布式执行
2. 量化方法（如minmax）支持分布式执行
3. 离群值抑制算法（如iter_smooth、flex_smooth）支持分布式执行
