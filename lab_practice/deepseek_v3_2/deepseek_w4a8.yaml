apiversion: modelslim_v1
metadata:
  config_id: deepseek_w4a8
  score: 90
  verified_model_types:
    - DeepSeek-V3.2-Exp
  label:
    w_bit: 4
    a_bit: 8
    is_sparse: False
    kv_cache: False

default_w4a8_dynamic: &default_w4a8_dynamic
  act:
    scope: "per_token"
    dtype: "int8"
    symmetric: True
    method: "minmax"
  weight:
    scope: "per_channel"
    dtype: "int4"
    symmetric: True
    method: "ssz"

default_w8a8_dynamic: &default_w8a8_dynamic
  act:
    scope: "per_token"
    dtype: "int8"
    symmetric: True
    method: "minmax"
  weight:
    scope: "per_channel"
    dtype: "int8"
    symmetric: True
    method: "minmax"

spec:
  process:
    - type: "quarot"
    - type: "flex_awq_ssz"
      qconfig:
        act:
          scope: "per_token"
          dtype: "int8"
          symmetric: True
          method: "minmax"
        weight:
          scope: "per_channel"
          dtype: "int4"
          symmetric: True
          method: "ssz"
          ext:
            step: 10
      enable_subgraph_type:
        - 'up-down'
      include:
        - "*"
      exclude:
        - "model.layers.0.*"
        - "model.layers.1.*"
        - "model.layers.2.*"
        - "*mlp.shared_experts.*"
    - type: "flex_smooth_quant"
      enable_subgraph_type:
        - 'norm-linear'
        - 'ov'
        - 'up-down'
      include:
        - "*self_attn*"
        - "model.layers.0.mlp.*"
        - "model.layers.1.mlp.*"
        - "model.layers.2.mlp.*"
        - "*mlp.shared_experts.*"
        - "*input_layernorm*"
      exclude:
        - "*post_attention_layernorm*"
    - type: "group"
      configs:
        - type: "linear_quant"
          qconfig: *default_w8a8_dynamic
          include:
            - "*self_attn*"
          exclude:
            - "*q_a_proj"
            - "*kv_a_proj*"
            - "*kv_b_proj"
            - "*wq_b"
            - "*wk"
            - "*weights_proj"
        - type: "linear_quant"
          qconfig: *default_w8a8_dynamic
          include:
            - "*mlp*"
          exclude:
            - "*gate"
            - "*mlp.experts.*"
        - type: "linear_quant"
          qconfig: *default_w8a8_dynamic
          include:
            - "model.layers.61.mlp.experts.*"
        - type: "linear_quant"
          qconfig: *default_w4a8_dynamic
          include:
            - "*mlp.experts.*"
          exclude:
            - "model.layers.61.*"
  dataset: qwen3_cot_w4a4.json
  save:
    - type: "ascendv1_saver"
      part_file_size: 4

